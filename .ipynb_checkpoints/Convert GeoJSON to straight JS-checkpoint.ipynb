{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to grab and store the Zillow data as GeoJSON ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Windermere\n",
      "Processing Laurelhurst\n",
      "Processing University District\n",
      "Processing Eastlake\n",
      "Processing South Lake Union\n",
      "Processing Lawton Park\n",
      "Processing Alki\n",
      "Processing Fauntleroy\n",
      "Processing Montlake\n",
      "Processing Stevens\n",
      "Processing Adams\n",
      "Processing Wallingford\n",
      "Processing Briarcliff\n",
      "Processing Industrial District\n",
      "Processing Whittier Heights\n",
      "Processing West Queen Anne\n",
      "Processing Mount Baker\n",
      "Processing Roxhill\n",
      "Processing Seward Park\n",
      "Processing Madison Park\n",
      "Processing North Beach/Blue Ridge\n",
      "Processing Green Lake\n",
      "Processing Sand Point\n",
      "Processing North Beacon Hill\n",
      "Processing Loyal Heights\n",
      "Processing Lower Queen Anne\n",
      "Processing West Woodland\n",
      "Processing Greenwood\n",
      "Processing Phinney Ridge\n",
      "Processing Fremont\n",
      "Processing View Ridge\n",
      "Processing Bitter Lake\n",
      "Processing Ravenna\n",
      "Processing Bryant\n",
      "Processing Mann\n",
      "Processing Roosevelt\n",
      "Processing Southeast Magnolia\n",
      "Processing East Queen Anne\n",
      "Processing North Queen Anne\n",
      "Processing Westlake\n",
      "Processing Minor\n",
      "Processing Madrona\n",
      "Processing Maple Leaf\n",
      "Processing International District\n",
      "Processing Harrison/Denny-Blaine\n",
      "Processing Leschi\n",
      "Processing Atlantic\n",
      "Processing Yesler Terrace\n",
      "Processing Pike-Market\n",
      "Processing High Point\n",
      "Processing Belltown\n",
      "Processing Central Business District\n",
      "Processing First Hill\n",
      "Processing Pioneer Square\n",
      "Processing Interbay\n",
      "Processing Industrial District\n",
      "Processing Georgetown\n",
      "Processing South Park\n",
      "Processing Harbor Island\n",
      "Processing Seaview\n",
      "Processing Gatewood\n",
      "Processing Arbor Heights\n",
      "Processing North Admiral\n",
      "Processing Crown Hill\n",
      "Processing Brighton\n",
      "Processing Dunlap\n",
      "Processing Rainier Beach\n",
      "Processing Fairmount Park\n",
      "Processing Olympic Hills\n",
      "Processing Genesee\n",
      "Processing Mid-Beacon Hill\n",
      "Processing South Beacon Hill\n",
      "Processing Holly Park\n",
      "Processing South Delridge\n",
      "Processing Sunset Hill\n",
      "Processing Rainier View\n",
      "Processing Columbia City\n",
      "Processing Highland Park\n",
      "Processing Wedgwood\n",
      "Processing North Delridge\n",
      "Processing Riverview\n",
      "Processing Portage Bay\n",
      "Processing Broadway\n",
      "Processing Victory Heights\n",
      "Processing Matthews Beach\n",
      "Processing Broadview\n",
      "Processing Meadowbrook\n",
      "Processing Cedar Park\n",
      "Processing Haller Lake\n",
      "Processing Pinehurst\n",
      "Processing North College Park\n"
     ]
    }
   ],
   "source": [
    "## Try catting it to a geoJSON ##\n",
    "import xml.etree.ElementTree as ET\n",
    "import geojson\n",
    "import requests\n",
    "import time \n",
    "\n",
    "## Choose the file ##\n",
    "# poly = geojson.loads(open('neighborhood_prototype.geojson').read())\n",
    "\n",
    "# This is a JSON array of polygons, so it is a GeometryCollection #\n",
    "polys = geojson.loads(open('seattle_named_neighborhoods.geojson').read())\n",
    "\n",
    "# This is what I will output # \n",
    "poly_set = {}\n",
    "poly_set['type']     = 'FeatureCollection' # See (http://geojson.org/geojson-spec.html) \n",
    "poly_set['features'] = []                  # This holds each individual neighborhood polygon GeoJSON\n",
    "\n",
    "error_log = open('error_log.txt','w+')\n",
    "\n",
    "# How to iterate through each polygon #\n",
    "for poly in polys['features']:\n",
    "\t##\n",
    "\tname = poly['properties']['s_hood']\n",
    "\tprint('Processing ' + name )\n",
    "\t##\n",
    "\n",
    "\tneighborhood_poly = {}\n",
    "\tneighborhood_poly['type']     = 'Feature'        # 'Feature' is required when there are 'properties'\n",
    "\tneighborhood_poly['geometry'] = poly['geometry'] #  Maybe poly['type'] = 'MultiPolygon'\n",
    "\t#############\n",
    "\n",
    "\t## This dictionary holds stuff we want to append to our future GeoJSON ##\n",
    "\tneighborhood_data = {}\n",
    "\tneighborhood_data['name'] = name\n",
    "\n",
    "\t## Generating the request ##\n",
    "\tline = name.replace(' ', '%20')\n",
    "\tXML_request = 'http://www.zillow.com/webservice/GetDemographics.htm?zws-id=X1-ZWz1a9fsh24qh7_4n5nu&state=WA&city=Seattle&neighborhood=' + line\n",
    "\tneighborhood_data['XML_req'] = XML_request\n",
    "\n",
    "\t## Making and Parsing the request ##\n",
    "\n",
    "\tr = requests.get(XML_request)\n",
    "\n",
    "\t## Handling the request ##\n",
    "\n",
    "\tneighborhood_poly['properties'] = {}\n",
    "\t\t\n",
    "\ttry:\n",
    "\t\ttree = ET.fromstring(r.content)\n",
    "\n",
    "\t\t## Median Income and Median Commute Time ## \n",
    "\t\tfor attr_tag in tree.iter('attribute'):\n",
    "\t\t\tfor child in attr_tag:\n",
    "\t\t\t\t## \"Median Household Income\" ##\n",
    "\t\t\t\tif (child.text == 'Median Household Income'):\n",
    "\t\t\t\t\tfound = attr_tag\n",
    "\t\t\t\t\tmedian_income = found.find('values').find('neighborhood').find('value').text\n",
    "\t\t\t\t\t# print(median_income)\n",
    "\t\t\t\t\tneighborhood_data['Median_Household_Income'] = \"${:,.2f}\".format(float(median_income))\n",
    "\t\t\t\t## \"Average Commute Time (Minutes)\" ##\n",
    "\t\t\t\tif (child.text == 'Average Commute Time (Minutes)'):\n",
    "\t\t\t\t\tfound = attr_tag\n",
    "\t\t\t\t\tmedian_commute = found.find('values').find('neighborhood').find('value').text\n",
    "\t\t\t\t\t# print(median_commute)\n",
    "\t\t\t\t\tneighborhood_data['Median_Commute_Time']     = \"{:,.2f} minutes\".format(float(median_commute))\n",
    "\t\t\t\t\t\n",
    "\t\t\t## Transportation and Demographics ##\n",
    "\t\t\tfor cat_tag in tree.iter('category'):\n",
    "\t\t\t\tif cat_tag.attrib == {'type': 'Transportation'}:\n",
    "\t\t\t\t\ttransport_list = []\n",
    "\t\t\t\t\tfor child in cat_tag:\n",
    "\t\t\t\t\t\ttransport_list.append(child.text)\n",
    "\t\t\t\t\t# print(transport_list)\n",
    "\t\t\t\t\tneighborhood_data['Transportation'] = transport_list\n",
    "\t\t\t\tif cat_tag.attrib == {'type': 'Employment'}:  \n",
    "\t\t\t\t\temployment_list = []\n",
    "\t\t\t\t\tfor child in cat_tag:\n",
    "\t\t\t\t\t\temployment_list.append(child.text)\n",
    "\t\t\t\t\t#print(employment_list)\n",
    "\t\t\t\t\tneighborhood_data['Employment'] = employment_list\n",
    "            \n",
    "            ## Median Sale Price ##\n",
    "            \n",
    "            ## Demographics with Children ## \n",
    "\texcept:\n",
    "\t\terror_log.write('Unable to get result for ' + name + '\\n')\n",
    "\t\tneighborhood_poly['properties']['Zillow'] = 'Unable to retrieve Zillow Data.'\n",
    "        print('\\tUnable to resolve ' + name)\n",
    "\tfinally:\n",
    "\t\tfor key in neighborhood_data.keys():\n",
    "\t\t\tneighborhood_poly['properties'][key] = neighborhood_data[key]       \n",
    "\t\t#print(neighborhood_poly)\t\t\n",
    "\t\t## Add this to the global feature set ## \n",
    "\t\tpoly_set['features'].append(neighborhood_poly) ## Add this to the global feature set ##\n",
    "\t\ttime.sleep(2) ## This forces a 'sleep' of 2 seconds between requests. Necessary to avoid an IP ban ##\n",
    "\t\t\n",
    "error_log.close()\n",
    "\t\n",
    "### Output the GeoJSON at the End ###\n",
    "out_json = geojson.dumps(poly_set, sort_keys=True)\n",
    "out_file = open('all_Seattle_data_test.geojson','w+')\n",
    "out_file.write(out_json)\n",
    "out_file.close()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save each neighborhood into a JS polygon ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Save each polygon into a Javascript file that can be uploaded ##\n",
    "##     This was for testing a la (jsfiddle.net/bryan_weaver/akLBM/)\n",
    "\n",
    "for poly in my_data['features']:\n",
    "    n_name      = poly['properties']['s_hood']\n",
    "    if (n_name.find(' ') > 0 ):\n",
    "        n_name = n_name.replace(' ', '_')\n",
    "    if (n_name.find('/') > 0 ):\n",
    "        n_name = n_name.replace('/', ' ')\n",
    "    n_file_name = 'C:\\\\Hackathons\\\\work_orbit\\\\neighborhoods\\\\' + n_name + '.js'\n",
    "    n_file = open(n_file_name, 'w+')\n",
    "    n_file.write('var ' + n_name + ' = [' + '\\n')\n",
    "    ## Write out the coordinates ##\n",
    "    count      = 0\n",
    "    num_points = len(poly['geometry']['coordinates'][0][0])\n",
    "    \n",
    "    for p in poly['geometry']['coordinates'][0][0]:\n",
    "        count += 1\n",
    "        if (count < num_points):\n",
    "            n_file.write('\\t' + 'new google.maps.LatLng(' + str(p[1]) + ', ' + str(p[0]) + '),' + '\\n')\n",
    "        else:\n",
    "            n_file.write('\\t' + 'new google.maps.LatLng(' + str(p[1]) + ', ' + str(p[0]) + ')'  +  '\\n')\n",
    "    n_file.write('];')\n",
    "    n_file.close()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some examples of working with GeoJSON ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import geojson\n",
    "\n",
    "my_data = geojson.loads(open(\"seattle_named_neighborhoods.geojson\").read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['type', 'features']"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Look at the fields of the GeoJSON ##\n",
    "my_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FeatureCollection'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data['type']    # It is an array of Features, where each Feature contains a geometry and some properties #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(my_data['features']) # This shows the total number of neighborhoods in the GeoJSON #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## This writes out all the neigbhorhoods into a text file ##\n",
    "hood_list = open('neighborhood_list.txt', 'w+')\n",
    "for poly in my_data['features']:\n",
    "    hood_list.write(poly['properties']['s_hood'] + '\\n')\n",
    "hood_list.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## How to make an HTTP GET request ##\n",
    "import requests\n",
    "r = requests.get('http://www.zillow.com/webservice/GetDemographics.htm?zws-id=X1-ZWz1a9fsh24qh7_4n5nu&state=WA&city=Seattle&neighborhood=Maple%20Leaf')                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Look for something in the 200s to indicate success ##\n",
    "r.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Using the basic XML parser ##\n",
    "import xml.etree.ElementTree as ET\n",
    "tree = ET.fromstring(r.content)\n",
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'$50,372.72'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## How to format the monetary value ##\n",
    "\"${:,.2f}\".format(float(median_income))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## How to access attributes ##\n",
    "cat_tag.attrib == {'type': 'Transportation'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = requests.get(XML_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u's_hood': u'Windermere'}\n",
      "{u's_hood': u'Laurelhurst'}\n",
      "{u's_hood': u'University District'}\n",
      "{u's_hood': u'Eastlake'}\n",
      "{u's_hood': u'South Lake Union'}\n",
      "{u's_hood': u'Lawton Park'}\n",
      "{u's_hood': u'Alki'}\n",
      "{u's_hood': u'Fauntleroy'}\n",
      "{u's_hood': u'Montlake'}\n",
      "{u's_hood': u'Stevens'}\n",
      "{u's_hood': u'Adams'}\n",
      "{u's_hood': u'Wallingford'}\n",
      "{u's_hood': u'Briarcliff'}\n",
      "{u's_hood': u'Industrial District'}\n",
      "{u's_hood': u'Whittier Heights'}\n",
      "{u's_hood': u'West Queen Anne'}\n",
      "{u's_hood': u'Mount Baker'}\n",
      "{u's_hood': u'Roxhill'}\n",
      "{u's_hood': u'Seward Park'}\n",
      "{u's_hood': u'Madison Park'}\n",
      "{u's_hood': u'North Beach/Blue Ridge'}\n",
      "{u's_hood': u'Green Lake'}\n",
      "{u's_hood': u'Sand Point'}\n",
      "{u's_hood': u'North Beacon Hill'}\n",
      "{u's_hood': u'Loyal Heights'}\n",
      "{u's_hood': u'Lower Queen Anne'}\n",
      "{u's_hood': u'West Woodland'}\n",
      "{u's_hood': u'Greenwood'}\n",
      "{u's_hood': u'Phinney Ridge'}\n",
      "{u's_hood': u'Fremont'}\n",
      "{u's_hood': u'View Ridge'}\n",
      "{u's_hood': u'Bitter Lake'}\n",
      "{u's_hood': u'Ravenna'}\n",
      "{u's_hood': u'Bryant'}\n",
      "{u's_hood': u'Mann'}\n",
      "{u's_hood': u'Roosevelt'}\n",
      "{u's_hood': u'Southeast Magnolia'}\n",
      "{u's_hood': u'East Queen Anne'}\n",
      "{u's_hood': u'North Queen Anne'}\n",
      "{u's_hood': u'Westlake'}\n",
      "{u's_hood': u'Minor'}\n",
      "{u's_hood': u'Madrona'}\n",
      "{u's_hood': u'Maple Leaf'}\n",
      "{u's_hood': u'International District'}\n",
      "{u's_hood': u'Harrison/Denny-Blaine'}\n",
      "{u's_hood': u'Leschi'}\n",
      "{u's_hood': u'Atlantic'}\n",
      "{u's_hood': u'Yesler Terrace'}\n",
      "{u's_hood': u'Pike-Market'}\n",
      "{u's_hood': u'High Point'}\n",
      "{u's_hood': u'Belltown'}\n",
      "{u's_hood': u'Central Business District'}\n",
      "{u's_hood': u'First Hill'}\n",
      "{u's_hood': u'Pioneer Square'}\n",
      "{u's_hood': u'Interbay'}\n",
      "{u's_hood': u'Industrial District'}\n",
      "{u's_hood': u'Georgetown'}\n",
      "{u's_hood': u'South Park'}\n",
      "{u's_hood': u'Harbor Island'}\n",
      "{u's_hood': u'Seaview'}\n",
      "{u's_hood': u'Gatewood'}\n",
      "{u's_hood': u'Arbor Heights'}\n",
      "{u's_hood': u'North Admiral'}\n",
      "{u's_hood': u'Crown Hill'}\n",
      "{u's_hood': u'Brighton'}\n",
      "{u's_hood': u'Dunlap'}\n",
      "{u's_hood': u'Rainier Beach'}\n",
      "{u's_hood': u'Fairmount Park'}\n",
      "{u's_hood': u'Olympic Hills'}\n",
      "{u's_hood': u'Genesee'}\n",
      "{u's_hood': u'Mid-Beacon Hill'}\n",
      "{u's_hood': u'South Beacon Hill'}\n",
      "{u's_hood': u'Holly Park'}\n",
      "{u's_hood': u'South Delridge'}\n",
      "{u's_hood': u'Sunset Hill'}\n",
      "{u's_hood': u'Rainier View'}\n",
      "{u's_hood': u'Columbia City'}\n",
      "{u's_hood': u'Highland Park'}\n",
      "{u's_hood': u'Wedgwood'}\n",
      "{u's_hood': u'North Delridge'}\n",
      "{u's_hood': u'Riverview'}\n",
      "{u's_hood': u'Portage Bay'}\n",
      "{u's_hood': u'Broadway'}\n",
      "{u's_hood': u'Victory Heights'}\n",
      "{u's_hood': u'Matthews Beach'}\n",
      "{u's_hood': u'Broadview'}\n",
      "{u's_hood': u'Meadowbrook'}\n",
      "{u's_hood': u'Cedar Park'}\n",
      "{u's_hood': u'Haller Lake'}\n",
      "{u's_hood': u'Pinehurst'}\n",
      "{u's_hood': u'North College Park'}\n"
     ]
    }
   ],
   "source": [
    "## How to read out all the names ##\n",
    "polys = geojson.loads(open('seattle_named_neighborhoods.geojson').read())\n",
    "\n",
    "for poly in polys['features']:\n",
    "    print(poly['properties'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lat\n",
      "docks\n",
      "lng\n",
      "name\n",
      "address\n",
      "lat\n",
      "docks\n",
      "lng\n",
      "name\n",
      "address\n",
      "lat\n",
      "docks\n",
      "lng\n",
      "name\n",
      "address\n",
      "lat\n",
      "docks\n",
      "lng\n",
      "name\n",
      "address\n",
      "lat\n",
      "docks\n",
      "lng\n",
      "name\n",
      "address\n",
      "lat\n",
      "docks\n",
      "lng\n",
      "name\n",
      "address\n",
      "lat\n",
      "docks\n",
      "lng\n",
      "name\n",
      "address\n",
      "lat\n",
      "docks\n",
      "lng\n",
      "name\n",
      "address\n",
      "lat\n",
      "docks\n",
      "lng\n",
      "name\n",
      "address\n",
      "lat\n",
      "docks\n",
      "lng\n",
      "name\n",
      "address\n",
      "lat\n",
      "docks\n",
      "lng\n",
      "name\n",
      "address\n",
      "lat\n",
      "docks\n",
      "lng\n",
      "name\n",
      "address\n",
      "lat\n",
      "docks\n",
      "lng\n",
      "name\n",
      "address\n",
      "lat\n",
      "docks\n",
      "lng\n",
      "name\n",
      "address\n",
      "lat\n",
      "docks\n",
      "lng\n",
      "name\n",
      "address\n",
      "lat\n",
      "docks\n",
      "lng\n",
      "name\n",
      "address\n",
      "lat\n",
      "docks\n",
      "lng\n",
      "name\n",
      "address\n",
      "lat\n",
      "docks\n",
      "lng\n",
      "name\n",
      "address\n",
      "lat\n",
      "docks\n",
      "lng\n",
      "name\n",
      "address\n",
      "lat\n",
      "docks\n",
      "lng\n",
      "name\n",
      "address\n",
      "lat\n",
      "docks\n",
      "lng\n",
      "name\n",
      "address\n",
      "lat\n",
      "docks\n",
      "lng\n",
      "name\n",
      "address\n",
      "lat\n",
      "docks\n",
      "lng\n",
      "name\n",
      "address\n",
      "lat\n",
      "docks\n",
      "lng\n",
      "name\n",
      "address\n",
      "lat\n",
      "docks\n",
      "lng\n",
      "name\n",
      "address\n",
      "lat\n",
      "docks\n",
      "lng\n",
      "name\n",
      "address\n",
      "lat\n",
      "docks\n",
      "lng\n",
      "name\n",
      "address\n",
      "lat\n",
      "docks\n",
      "lng\n",
      "name\n",
      "address\n",
      "lat\n",
      "docks\n",
      "lng\n",
      "name\n",
      "address\n",
      "lat\n",
      "docks\n",
      "lng\n",
      "name\n",
      "address\n",
      "lat\n",
      "docks\n",
      "lng\n",
      "name\n",
      "address\n",
      "lat\n",
      "docks\n",
      "lng\n",
      "name\n",
      "address\n",
      "lat\n",
      "docks\n",
      "lng\n",
      "name\n",
      "address\n",
      "lat\n",
      "docks\n",
      "lng\n",
      "name\n",
      "address\n",
      "lat\n",
      "docks\n",
      "lng\n",
      "name\n",
      "address\n",
      "lat\n",
      "docks\n",
      "lng\n",
      "name\n",
      "address\n",
      "lat\n",
      "docks\n",
      "lng\n",
      "name\n",
      "address\n",
      "lat\n",
      "docks\n",
      "lng\n",
      "name\n",
      "address\n",
      "lat\n",
      "docks\n",
      "lng\n",
      "name\n",
      "address\n",
      "lat\n",
      "docks\n",
      "lng\n",
      "name\n",
      "address\n",
      "lat\n",
      "docks\n",
      "lng\n",
      "name\n",
      "address\n",
      "lat\n",
      "docks\n",
      "lng\n",
      "name\n",
      "address\n",
      "lat\n",
      "docks\n",
      "lng\n",
      "name\n",
      "address\n",
      "lat\n",
      "docks\n",
      "lng\n",
      "name\n",
      "address\n",
      "lat\n",
      "docks\n",
      "lng\n",
      "name\n",
      "address\n",
      "lat\n",
      "docks\n",
      "lng\n",
      "name\n",
      "address\n",
      "lat\n",
      "docks\n",
      "lng\n",
      "name\n",
      "address\n",
      "lat\n",
      "docks\n",
      "lng\n",
      "name\n",
      "address\n",
      "lat\n",
      "docks\n",
      "lng\n",
      "name\n",
      "address\n"
     ]
    }
   ],
   "source": [
    "## Add \"type\": \"pronto\" to the pronto station GSON ##\n",
    "\n",
    "## Try catting it to a geoJSON ##\n",
    "import xml.etree.ElementTree as ET\n",
    "import geojson\n",
    "import requests\n",
    "import time \n",
    "\n",
    "## Choose the file ##\n",
    "# poly = geojson.loads(open('neighborhood_prototype.geojson').read())\n",
    "\n",
    "# This is a JSON array of polygons, so it is a GeometryCollection #\n",
    "polys = geojson.loads(open('formatted_pronto_locations.geojson').read())\n",
    "\n",
    "# This is what I will output # \n",
    "poly_set = {}\n",
    "poly_set['type']     = 'FeatureCollection' # See (http://geojson.org/geojson-spec.html) \n",
    "poly_set['features'] = []                  # This holds each individual neighborhood polygon GeoJSON\n",
    "\n",
    "error_log = open('error_log.txt','w+')\n",
    "\n",
    "# How to iterate through each point feature #\n",
    "for poly in polys['features']:\n",
    "    \n",
    "    ## Make a new GeoJSON point ## \n",
    "\tpronto_poly = {}\n",
    "\tpronto_poly['type']       = 'Feature'        # 'Feature' is required when there are 'properties'\n",
    "\tpronto_poly['geometry']   = poly['geometry'] #  Maybe poly['type'] = 'MultiPolygon'\n",
    "\tpronto_poly['properties'] = {}\n",
    "\t#############    \n",
    "        \n",
    "\tfor key in poly['properties'].keys():\n",
    "\t\tpronto_poly['properties'][key] = poly['properties'][key]\n",
    "    \n",
    "    ## LABEL IT AS A PRONTO POINT ##\n",
    "    \n",
    "    pronto_poly['properties']['type'] = 'Pronto'\n",
    "\n",
    "\t## Add this to the global feature set ## \n",
    "\tpoly_set['features'].append(pronto_poly) \n",
    "    \n",
    "\t\n",
    "### Output the GeoJSON at the End ###\n",
    "out_json = geojson.dumps(poly_set, sort_keys=True)\n",
    "out_file = open('pronto_formatted_aug.geojson','w+')\n",
    "out_file.write(out_json)\n",
    "out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
